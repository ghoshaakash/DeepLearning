
\chapter{Why is language a pain to model? And how do we model them.}
\section{Language and ideas}
Language arose about $100,000-1,000,000$ years ago and that took us from Bronze Age to modern science. From a linguistic point of view, a word is the representation of an idea. Words representing old obsolete ideas are often forgotten, and new words representing new ideas. 


\section{Why is NLP hard?}
\textit{Written as a person fluent in English, Bengali and Hindi}\\
The short answer is when we speak, we leave out massive chunks of information. A lot of the information  conveyed while writing assumes that the reader has prior context and experience to extract meaningful information from the text. It is even more difficult when looking at transcriptions of spoken text: While speaking we use our facial expressions and vocal tones as a part of communication.  Some particular difficulties are described below:
\begin{enumerate}
    \item Homonyms: When we say "He/She is cool" we often mean that a person is calm and collected. We use our prior experience to infer "cool" is not referring to feeling coldness. Ideally, we would like our model to understand such subtleties. More examples include:
    \begin{itemize}
        \item \textbf{Iraqi Head Seeks Arms}: Here head is to be interpreted as leader and not as body part. 
        \item \textbf{Kids Make Nutritious Snacks}: Here make is to be understood as the process of creation and is not meant as a part of. 
        \item \textbf{Miners Refuse to Work after Death}: Here death refers to death of a person and not the state of being dead.
    \end{itemize}
    \item For complex sentences we use prior experiences for deciphering meaning. This process is made more complex by the fact that in English language, a single word can act as different parts of speech. For example, 
    \begin{itemize}
        \item \textbf{Enraged Cow Injures Farmer with Ax}: the with ax part is describing the farmer and not the cow.
        \item \textbf{Hospitals are Sued by 7 Foot Doctors}: The phrase"7 foot" are two different ideas: 7 describes the number of doctors and foot describes their specialty of work. 
        \item \textbf{Students cook and serve grandparents}: Grandparents are served food, they are not the food
    \end{itemize}
    More examples are available here:\\
    \verb|https://www.plainlanguage.gov/resources/humor/funny-headlines/|
    \item Figures of speech: We use the example of sarcasm. When we use sarcasm we mean the opposite of what we say. We again use prior experience to identify that the writer doesn't mean what they say. For example, consider a very simple case: "Great! Now my tires are flat". We use our prior knowledge that a flat tire (in most cases) is not a desirable thing and so the word "great" is not used in a positive sense. Things get tricker when this is used in more subtle sense.
    \item Not all ideas are available in all languages: As a very artificial example, no $16^{th}$ century Indian language would have a word for potato simply because no one knew what a potato was! Some more examples are available here:\\ \verb|https://www.babbel.com/en/magazine/untranslatable-01|
    \item As someone once said, language is a living thing. New words are always being made to represent new ideas and the internet has accelerated this process. Words like Poggers, KEKW, OC etc. were invented in the era of memes and twitch chat. Usage of unalive (which was not an actual word some time ago) is gaining popularly as the actual word "dead" is often flagged by online platforms. 
\end{enumerate}




\section{Context and Lexical semantics}
Each word represents an idea, and when we communicate we chain those ideas. This gives rise to the idea of context. We claim a word gets it's meaning from the words surrounding it. For example, if we have a new word \textbf{plompyskompy} and we say it is used as follows: "There is an apple \textbf{plompyskompy} on the table" you might (again, due to your experience) understand it represents same kind of idea the word "on"  represents. You understand this due to the words surrounding it.  This leads us to the idea of Lexical semantics(Ref: \verb|https://en.wikipedia.org/wiki/Lexical_semantics|)



\section{Language as a Markov process}
This will now be a quick discussion. A word gets it's meaning from its surrounding words. The rest of the corpus doesn't matter. What came 100 words ago doesn't matter(unless we are considering what came 100 words ago to be a part of the context of the word). We look at the last few words and by our theory, it should be enough to predict what our next word is going to be. Therefore, if we are looking at a context window of $n$ words then it should be modelled as an $n^{th}$ order Markov chain. Ref:\\\verb|https://www.cs.princeton.edu/courses/archive/spr05/cos126/assignments/markov.html|

\section{Language as a stochastic process}
Languages can also be modelled as stochastic process, i.e. we drop the assumption that local context is all that is needed. And it should be noted that the memoryless property of Markov processes are counterintuitive to our claim that experience plays an important role in decoding ideas from sentences. Ref: \verb|https://openreview.net/forum?id=pMQwKL1yctf|

\section{Crude early models and their shortcomings}

 Traditionally, a computer understands a word by using a dictionary and looking up synonyms(word with similar meaning), hypernyms(expression of belonging to a more general category), hyponyms(expression of belonging to more specific subclass). A minimal example implemented in NLTK is shown below. Some arrays are truncated for brevity.
    \begin{lstlisting}
        >>> from nltk.corpus import wordnet as wn
        >>> wn.synonyms('car')
        [['auto', 'automobile', 'machine', 'motorcar'], ['railcar', 'railroad_car', 'railway_car'], ['gondola'], ['elevator_car'], ['cable_car']]
        >>> wn.synsets('car')[:2]
        [Synset('car.n.01'), Synset('car.n.02')]
        >>> wn.synset('car.n.01').definition()
        'a motor vehicle with four wheels; usually propelled by an internal combustion engine'
        >>> wn.synset('car.n.01').examples()
        ['he needs a car to get to work']
        >>> wn.synset('car.n.01').hypernyms()
        [Synset('motor_vehicle.n.01')]
        >>> wn.synset('dog.n.01').hypernyms()    
        [Synset('canine.n.02'), Synset('domestic_animal.n.01')]
        >>> wn.synset('car.n.01').hyponyms()[:5]
        [Synset('ambulance.n.01'), Synset('beach_wagon.n.01'), Synset('bus.n.04'), Synset('cab.n.03'), Synset('compact.n.03')]
    \end{lstlisting}
But this is not a very robust solution: dependency on context and nuances are not resolved(Ex: "crimson" is a synonym of "red" but "the color of an apple is crimson" is a weird sounding sentence).  Moreover, language is ever-changing and keeping track of an ever changing 
    \begin{marginfigure}%
        
    \end{marginfigure}%
In traditional bag of words approach, words are given a one hot vector representation. For example:
\begin{align*}
    \text{"hotel"}=[0,0,0,0,0,1,0,0,0]\\
    \text{"motel"}=[0,0,0,0,0,0,0,1,0]
\end{align*}
But this approach has its own limitations:
\begin{enumerate}
    \item Vector size increase with increase in vocabulary
    \item We understand that the words above are similar, but that similarity is not reflected in such one-hot encoding.
\end{enumerate}



